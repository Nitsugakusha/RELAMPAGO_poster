{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = pd.read_csv('base_corr.csv')\n",
    "#tw_rock =  pd.read_csv('Twitter_Rock.csv')\n",
    "msj = tw['Twit']\n",
    "tag = tw['Tag']\n",
    "\n",
    "#msj_rock =  tw_rock['Message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 80\n",
    "\n",
    "\n",
    "data_si = [(i.split(),j) for i,j in zip(list(msj)[1:1+size],list(tag)[1:1+size])]\n",
    "\n",
    "#data_no = [(i.split(),'No Meteorologico') for i in list(msj_rock)[:size]]\n",
    "\n",
    "data = data_si \n",
    "\n",
    "test_si = [(i.split(),j) for i,j in zip(list(msj)[1+size:1+2*size],list(tag)[1+size:1+2*size])]\n",
    "\n",
    "\n",
    "test_data = test_si \n",
    "\n",
    "label_to_ix = { 1: 0, 0: 1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = {}\n",
    "for sent, _ in data + test_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "#print (word_to_ix,len(word_to_ix))\n",
    "\n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoWClassifier(nn.Module): # inheriting from nn.Module!\n",
    "    \n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        \n",
    "        super(BoWClassifier, self).__init__()\n",
    "\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "        \n",
    "        \n",
    "    def forward(self, bow_vec):\n",
    "        # Pass the input through the linear layer,\n",
    "        # then pass that through log_softmax.\n",
    "        # Many non-linearities and other functions are in torch.nn.functional\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)\n",
    "    \n",
    "    def make_bow_vector(sentence, word_to_ix):\n",
    "        vec = torch.zeros(len(word_to_ix))\n",
    "        for word in sentence:\n",
    "            vec[word_to_ix[word]] += 1\n",
    "        return vec.view(1, -1)\n",
    "\n",
    "    def make_target(label, label_to_ix):\n",
    "        \n",
    "        return torch.LongTensor([label_to_ix[label]])\n",
    "    \n",
    "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(BoWClassifier.make_bow_vector('me me gusta comer en la cafeteria'.split(),word_to_ix))\n",
    "\n",
    "\n",
    "#for param in model.parameters():\n",
    "    #print (param)\n",
    "    \n",
    "# To run the model, pass in a BoW vector, but wrapped in an autograd.Variable\n",
    "sample = data[0]\n",
    "#print (sample)\n",
    "bow_vector = BoWClassifier.make_bow_vector(sample[0], word_to_ix)\n",
    "#print(bow_vector)\n",
    "log_probs = model(bow_vector)\n",
    "#print (log_probs.exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4996, 0.5004]], grad_fn=<ExpBackward>) Meteorologico\n",
      "tensor([[0.5524, 0.4476]], grad_fn=<ExpBackward>) Meteorologico\n",
      "tensor([[0.4790, 0.5210]], grad_fn=<ExpBackward>) Meteorologico\n",
      "tensor([[0.4978, 0.5022]], grad_fn=<ExpBackward>) Meteorologico\n",
      "tensor([[0.4516, 0.5484]], grad_fn=<ExpBackward>) Meteorologico\n",
      "tensor([[0.4944, 0.5056]], grad_fn=<ExpBackward>) Meteorologico\n",
      "tensor([[0.4853, 0.5147]], grad_fn=<ExpBackward>) Meteorologico\n",
      "tensor([[0.4870, 0.5130]], grad_fn=<ExpBackward>) Meteorologico\n",
      "tensor([[0.5034, 0.4966]], grad_fn=<ExpBackward>) Meteorologico\n",
      "tensor([[0.4322, 0.5678]], grad_fn=<ExpBackward>) Meteorologico\n",
      "tensor([[0.5200, 0.4800]], grad_fn=<ExpBackward>) No Meteorologico\n",
      "tensor([[0.5228, 0.4772]], grad_fn=<ExpBackward>) No Meteorologico\n",
      "tensor([[0.5229, 0.4771]], grad_fn=<ExpBackward>) No Meteorologico\n",
      "tensor([[0.5427, 0.4573]], grad_fn=<ExpBackward>) No Meteorologico\n",
      "tensor([[0.4567, 0.5433]], grad_fn=<ExpBackward>) No Meteorologico\n",
      "tensor([[0.4756, 0.5244]], grad_fn=<ExpBackward>) No Meteorologico\n",
      "tensor([[0.4906, 0.5094]], grad_fn=<ExpBackward>) No Meteorologico\n",
      "tensor([[0.4554, 0.5446]], grad_fn=<ExpBackward>) No Meteorologico\n",
      "tensor([[0.4915, 0.5085]], grad_fn=<ExpBackward>) No Meteorologico\n",
      "tensor([-0.0033, -0.0390], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Run on test data before we train, just to see a before-and-after\n",
    "for instance, label in test_data:\n",
    "    bow_vec = BoWClassifier.make_bow_vector(instance, word_to_ix)\n",
    "    log_probs = model(bow_vec)\n",
    "    print (log_probs.exp(), label)\n",
    "print (next(model.parameters())[:,word_to_ix[\"lluvia\"]]) # Print the matrix column corresponding to \"creo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 10\n",
      "Epoch: 20\n",
      "Epoch: 30\n",
      "Epoch: 40\n",
      "Epoch: 50\n",
      "Epoch: 60\n",
      "Epoch: 70\n",
      "Epoch: 80\n",
      "Epoch: 90\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Usually you want to pass over the training data several times.\n",
    "# 100 is much bigger than on a real data set, but real datasets have more than\n",
    "# two instances.  Usually, somewhere between 5 and 30 epochs is reasonable.\n",
    "for epoch in range(100):\n",
    "    if epoch % 10 == 0: print('Epoch: %i' %epoch)\n",
    "    for instance, label in data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.  We need to clear them out\n",
    "        # before each instance\n",
    "        model.zero_grad()\n",
    "    \n",
    "        # Step 2. Make our BOW vector and also we must wrap the target in a Variable\n",
    "        # as an integer.  For example, if the target is SPANISH, then we wrap the integer\n",
    "        # 0.  The loss function then knows that the 0th element of the log probabilities is\n",
    "        # the log probability corresponding to SPANISH\n",
    "        bow_vec = BoWClassifier.make_bow_vector(instance, word_to_ix)\n",
    "        target = BoWClassifier.make_target(label, label_to_ix)\n",
    "    \n",
    "        # Step 3. Run our forward pass.\n",
    "        log_probs = model(bow_vec)\n",
    "    \n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by calling\n",
    "        # optimizer.step()\n",
    "        loss = loss_function(log_probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m tensor([[0.7617, 0.2383]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;32m tensor([[0.0024, 0.9976]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;32m tensor([[0.0664, 0.9336]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;32m tensor([[0.0020, 0.9980]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;31m tensor([[0.9628, 0.0372]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;93m tensor([[0.9803, 0.0197]], grad_fn=<ExpBackward>) 1\n",
      "\u001b[1;31m tensor([[0.9288, 0.0712]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;32m tensor([[0.0045, 0.9955]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;31m tensor([[0.7173, 0.2827]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;32m tensor([[0.0023, 0.9977]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;31m tensor([[0.6250, 0.3750]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;31m tensor([[0.6936, 0.3064]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;93m tensor([[0.6626, 0.3374]], grad_fn=<ExpBackward>) 1\n",
      "\u001b[1;32m tensor([[0.2965, 0.7035]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;31m tensor([[0.8798, 0.1202]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;31m tensor([[0.9445, 0.0555]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;31m tensor([[0.2007, 0.7993]], grad_fn=<ExpBackward>) 1\n",
      "\u001b[1;31m tensor([[0.5586, 0.4414]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;32m tensor([[0.2385, 0.7615]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;31m tensor([[0.4090, 0.5910]], grad_fn=<ExpBackward>) 1\n",
      "\u001b[1;31m tensor([[0.6773, 0.3227]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;32m tensor([[0.0119, 0.9881]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;32m tensor([[0.0038, 0.9962]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;31m tensor([[0.6800, 0.3200]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;31m tensor([[0.8140, 0.1860]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;32m tensor([[0.3211, 0.6789]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;32m tensor([[0.2439, 0.7561]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;32m tensor([[0.2232, 0.7768]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;31m tensor([[0.8370, 0.1630]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;31m tensor([[0.3367, 0.6633]], grad_fn=<ExpBackward>) 1\n",
      "\u001b[1;93m tensor([[0.8791, 0.1209]], grad_fn=<ExpBackward>) 1\n",
      "\u001b[1;31m tensor([[0.6181, 0.3819]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;32m tensor([[0.0082, 0.9918]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;93m tensor([[0.9265, 0.0735]], grad_fn=<ExpBackward>) 1\n",
      "\u001b[1;31m tensor([[0.6921, 0.3079]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;32m tensor([[0.4793, 0.5207]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;32m tensor([[0.4771, 0.5229]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;93m tensor([[0.6985, 0.3015]], grad_fn=<ExpBackward>) 1\n",
      "\u001b[1;93m tensor([[0.8907, 0.1093]], grad_fn=<ExpBackward>) 1\n",
      "\u001b[1;31m tensor([[0.3791, 0.6209]], grad_fn=<ExpBackward>) 1\n",
      "\u001b[1;32m tensor([[4.6098e-04, 9.9954e-01]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;31m tensor([[0.7767, 0.2233]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;32m tensor([[0.0049, 0.9951]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;31m tensor([[0.8949, 0.1051]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;32m tensor([[0.0040, 0.9960]], grad_fn=<ExpBackward>) 0\n",
      "\u001b[1;31m tensor([[0.3023, 0.6977]], grad_fn=<ExpBackward>) 1\n",
      "\u001b[1;32m tensor([[0.0413, 0.9587]], grad_fn=<ExpBackward>) 0\n",
      "De aciertos Meteorológicos:  6 %, De No Meteorologicos:  19 %, de Fallas:  22 %\n",
      "[6, 19, 22]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 3 artists>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = [0,0,0]\n",
    "for instance, label in test_data:\n",
    "    bow_vec = autograd.Variable(BoWClassifier.make_bow_vector(instance, word_to_ix))\n",
    "    log_probs = model(bow_vec)\n",
    "    log_probs_exp = log_probs.exp()\n",
    "    if bool (log_probs_exp[0][0]>0.5) and (label == 1):\n",
    "        c[0]+=1\n",
    "        print ('\\033[1;93m' , log_probs_exp , label)\n",
    "    elif bool (log_probs_exp[0][1]>0.5) and (label == 0):\n",
    "        c[1]+=1\n",
    "        print ('\\033[1;32m' , log_probs_exp , label)\n",
    "    else:\n",
    "        c[2]+=1\n",
    "        print ('\\033[1;31m' , log_probs_exp , label)\n",
    " \n",
    "print('De aciertos Meteorológicos: ', round(c[0]),'%, De No Meteorologicos: ', round(c[1]), '%, de Fallas: ', round(c[2]),'%') \n",
    "print(c)\n",
    "#print ('\\033[0m', next(model.parameters())[:,word_to_ix[\"lluvia\"]]) # Index corresponding to Spanish goes up, English goes down!\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(3),c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9668, 0.0332]], grad_fn=<ExpBackward>)\n"
     ]
    }
   ],
   "source": [
    "instance = 'concierto de Rock en la ciudad'.split()\n",
    "\n",
    "bow_vec = autograd.Variable(BoWClassifier.make_bow_vector(instance, word_to_ix))\n",
    "log_probs = model(bow_vec)\n",
    "log_probs_exp = log_probs.exp()\n",
    "\n",
    "print(log_probs_exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
